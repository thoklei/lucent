{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import imageio\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lucent.optvis import render, param, objectives\n",
    "from lucent.modelzoo import inceptionv1\n",
    "from lucent.modelzoo.util import get_model_layers\n",
    "from lucent.optvis.render import pixelwise_gradient_change_interrupt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")\n",
    "\n",
    "param_f = lambda: param.image(224, batch=9)\n",
    "opt = lambda params: torch.optim.Adam(params, 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting googlenet\n",
    " \n",
    "model = inceptionv1(pretrained=True)\n",
    "model.to(device).eval()\n",
    "\n",
    "layer = \"mixed3a_1x1_pre_relu_conv\" # \"mixed5b_pool_reduce_pre_relu_conv\" #  \"mixed3a_1x1_pre_relu_conv\" # \"mixed5b_pool_reduce_pre_relu_conv\" # \n",
    "channel = 34 # 63 # 34\n",
    "diversity_alpha = 100 # 6062.5 # super large objective which should hinder optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively, getting resnet50\n",
    "\n",
    "from resnet import get_resnet\n",
    "model = get_resnet(\"standard\", device) \n",
    "\n",
    "layer = \"layer3_1_conv3\" #\"layer4_1_conv3\" # \"layer3_1_conv3\"\n",
    "channel = 42\n",
    "diversity_alpha = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = objectives.channel(layer, channel)\n",
    "# obj -= diversity_alpha * objectives.diversity(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems to work well for both model types\n",
    "\n",
    "# to get the gradients, uncomment the return statement in render.py\n",
    "\n",
    "images, raw_grads = render.render_vis(model, obj, param_f, opt, thresholds=(20000,), verbose=True, layer=layer, channel=channel, min_steps=2500, interrupt_interval=1, interrupt_condition=pixelwise_gradient_change_interrupt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradfile = f\"{layer}__{channel}__grads_l2_resnet.pkl\"\n",
    "\n",
    "with open(gradfile, \"wb\") as f:\n",
    "    pickle.dump(raw_grads, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer = \"mixed5b_pool_reduce_pre_relu_conv\" #  \"mixed3a_1x1_pre_relu_conv\" # \"mixed5b_pool_reduce_pre_relu_conv\" # \n",
    "#channel = 63 # 34\n",
    "#diversity_alpha = 6062.5 # super large objective which should hinder optimization\n",
    "\n",
    "filename = f\"{layer}__{channel}__grads_l2_resnet.pkl\"\n",
    "\n",
    "with open(filename, \"rb\") as f:\n",
    "    grads = pickle.load(f)\n",
    "\n",
    "\n",
    "def ratio(sequence):\n",
    "    winsize = 2000\n",
    "\n",
    "    # continue if we haven't even collected enough values\n",
    "    if len(sequence) < winsize:\n",
    "        return 2\n",
    "\n",
    "    first_half = np.mean(sequence[-winsize:-winsize//2])\n",
    "    second_half = np.mean(sequence[-winsize//2:])\n",
    "\n",
    "    ratio = first_half / second_half\n",
    "\n",
    "    return ratio\n",
    "\n",
    "\n",
    "def smooth(scalars, weight: float):  # Weight between 0 and 1\n",
    "    last = scalars[0]  # First value in the plot (first timestep)\n",
    "    smoothed = list()\n",
    "    for point in scalars:\n",
    "        smoothed_val = last * weight + (1 - weight) * point  # Calculate smoothed value\n",
    "        smoothed.append(smoothed_val)                        # Save it\n",
    "        last = smoothed_val                                  # Anchor the last smoothed value\n",
    "\n",
    "    return smoothed\n",
    "\n",
    "\n",
    "def plot_grads(grads):\n",
    "    xs = list(range(len(grads)))\n",
    "    ratios = [ratio(grads[:i]) for i in range(len(grads))]\n",
    "    #smoothed = smooth(grads, 0.99) #[np.mean(grads[idx-win:idx+win]) for idx in range(win, len(acts)-win)]\n",
    "\n",
    "    start = 500\n",
    "    xs = xs[start:]\n",
    "    grads = grads[start:]\n",
    "    ratios = ratios[start:]\n",
    "    #smoothed = smoothed[start:]\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    plt.title(f\"Mean pixelwise grads for {layer}__{channel}, alpha {diversity_alpha}\")\n",
    "\n",
    "    ax1.set_xlabel(\"Optimization Steps\")\n",
    "    ax1.set_ylabel(\"Mean pixelwise grad\")\n",
    "    #ax1.set_yscale('log')\n",
    "    # ax1.set_ylim(0, 30)\n",
    "\n",
    "    ax1.plot(xs, grads)\n",
    "    #ax1.plot(xs, smoothed)\n",
    "    #ax1.plot(xs, [8]*len(xs), c='r')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel(\"Ratio between windows\")\n",
    "    ax2.plot(xs, ratios, c='g')\n",
    "    ax2.set_ylim(1, 1.5)\n",
    "    ax2.plot(xs, [1.1]*len(xs), c='r')\n",
    "\n",
    "    plt.show()\n",
    "    #plt.savefig(f\"activations_{layer}_{channel}.png\")\n",
    "    plt.close()\n",
    "\n",
    "plot_grads(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('standard')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47ba74dac42e143af704e1f99c5fb09010a5cdca8bd83b0d1f595774210bb551"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
