{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lucent.optvis import render, param, objectives\n",
    "from lucent.modelzoo import inceptionv1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def store_images(images, location):\n",
    "    \"\"\"\n",
    "    Stores list of images for unit at location. \n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(location, exist_ok=True)\n",
    "\n",
    "    for idx, img in enumerate(images):\n",
    "        filename = f\"image_{idx}.png\"\n",
    "        imageio.imwrite(os.path.join(location, filename), np.uint8(img*255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_norm_interrupt(optimizer, params):\n",
    "    \"\"\"\n",
    "    Interrupts the optimization process once gradient norms are smaller than 7,\n",
    "    which is an empirically found value at which the optimization has reached colorful images.\n",
    "    \"\"\"\n",
    "    return render.gradient_norm_interrupt(optimizer, params, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")\n",
    "model = inceptionv1(pretrained=True)\n",
    "model.to(device).eval()\n",
    "\n",
    "param_f = lambda: param.image(224, batch=9)\n",
    "opt = lambda params: torch.optim.Adam(params, 5e-2)\n",
    "layer = \"mixed3a_1x1_pre_relu_conv\" # \"mixed5b_pool_reduce_pre_relu_conv\"\n",
    "channel = 34 # 63\n",
    "obj = objectives.channel(layer, channel)\n",
    "\n",
    "diversity_alpha = 100 #6062.5 # super large objective which should hinder optimization\n",
    "obj -= diversity_alpha * objectives.diversity(layer)\n",
    "\n",
    "images, grad_norms = render.render_vis(model, obj, param_f, opt, thresholds=(20000,), verbose=True, interrupt_interval=1, interrupt_condition=grad_norm_interrupt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{layer}__{channel}__gradnorms.pkl\", \"wb\") as f:\n",
    "    pickle.dump(grad_norms, f)\n",
    "\n",
    "#with open(f\"{layer}__{channel}__gradnorms.pkl\", \"rb\") as f:\n",
    "#    grad_norms = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only show the relevant parts of the graph\n",
    "xs = list(range(len(grad_norms)))\n",
    "start = 10_000\n",
    "grad_norms = grad_norms[start:]\n",
    "xs = xs[start:]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f\"Grad Norm for {layer}__{channel}, alpha {diversity_alpha}\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylabel(\"Mean Gradient Norm\")\n",
    "#plt.yscale('log')\n",
    "plt.ylim(1, 20)\n",
    "\n",
    "plt.plot(xs, grad_norms)\n",
    "plt.plot(xs, [8]*len(grad_norms))\n",
    "plt.plot(xs, [7]*len(grad_norms))\n",
    "#plt.savefig(\"grad_norms.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(np.min(grad_norms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('standard')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47ba74dac42e143af704e1f99c5fb09010a5cdca8bd83b0d1f595774210bb551"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
